# -*- coding: utf-8 -*-
"""Imdb.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XjBHN9sY5LXbZTGjp7fleW2C1Cx-rGs5
"""

# Commented out IPython magic to ensure Python compatibility.
# %reload_ext autoreload
# %autoreload 2
# %matplotlib inline

!pip install -q transformers[sentencepiece] fastbook fastai ohmeow-blurr nbdev

import torch
from transformers import AutoModelForSequenceClassification, AutoConfig
from fastai.text.all import *
from blurr.text.data.all import *
from blurr.text.modeling.all import *

import json
  

f = open('/content/drive/MyDrive/Imdb_data/imdb.json')
data = json.load(f)

print(data)

import pandas as pd
df = pd.DataFrame(data=data, columns=data[0].keys())
df.tail(2)

df['genres'][0]

genres_list = df.genres.to_list()

genre_count = {}
for genres in genres_list:
  genre_list = eval(str(genres))
  for genre in genre_list:
    if genre in genre_count.keys():
      genre_count[genre] += 1
    else:
      genre_count[genre] = 1
print(f"Number of Genres: {len(genre_count)}")
print(genre_count)

threshold = int(len(df) * 0.02)
rare_genres = [key for key, value in genre_count.items() if value < threshold]
len(rare_genres), rare_genres[:5]

genres_list = df.genres.to_list()
revised_genre_list = []
indices_to_drop = []

for idx, genres in enumerate(genres_list):
  genre_list = eval(str(genres))
  revised_genres = []

  for genre in genre_list:
    if genre not in rare_genres:
      revised_genres.append(genre)

  if len(revised_genres) == 0:
    indices_to_drop.append(idx)
  else:
    revised_genre_list.append(revised_genres)

df = df.drop(indices_to_drop).reset_index(drop=True)
df.shape

df['revised_genres'] = revised_genre_list

df.tail(2)

revised_genres_list = df.revised_genres.to_list()
revised_genre_count = {}
for genres in revised_genres_list:
  genre_list = genres
  for genre in genre_list:
    if genre in revised_genre_count.keys():
      revised_genre_count[genre] += 1
    else:
      revised_genre_count[genre] = 1
print(f"Number of Genres: {len(revised_genre_count)}")
print(revised_genre_count)

encode_genre_types = { key: idx for idx, (key, value) in enumerate(revised_genre_count.items())}
with open("/content/drive/MyDrive/imdb_everything/genre_types_encoded.json", "w") as fp:
  json.dump(encode_genre_types, fp)

# We need this because for multilabel classification all genres have possibility to be present in the predictions
categorical_genre_list = []
revised_genres_list = df.revised_genres.to_list()

for revised_genres in revised_genres_list:
  categorical_list = [0] * len(encode_genre_types)
  for genre in revised_genres:
    genre_type_index = encode_genre_types[genre] 
    categorical_list[genre_type_index] = 1
  categorical_genre_list.append(categorical_list)

categorical_genre_list[3][:16]

df['genre_cat_list'] = categorical_genre_list
df.head()

"""# Dataloaders and Modeling """

labels = list(encode_genre_types.keys())

model_name = "distilroberta-base"
model_cls = AutoModelForSequenceClassification
config = AutoConfig.from_pretrained(model_name)
config.num_labels = len(labels)

hf_arch, hf_config, hf_tokenizer, hf_model = get_hf_objects(model_name, model_cls=model_cls, config=config)
hf_model.config.problem_type = "multi_label_classification"

blocks = (TextBlock(hf_arch, hf_config, hf_tokenizer, hf_model), MultiCategoryBlock(encoded=True,vocab=labels))
dblock = DataBlock(blocks=blocks, get_x=ColReader('description'), get_y=ColReader('genre_cat_list'), splitter=RandomSplitter(valid_pct=0.1, seed=42))

dls = dblock.dataloaders(df, bs=32)
torch.save(dls, "/content/drive/MyDrive/imdb_everything/dataloaders/dls-multilabel-imdb-classifier.pkl")

# dls = torch.load("dataloaders/dls-multilabel-book-classifier.pkl")

dls.vocab

dls.show_batch(dataloaders=dls, max_n=4, trunc_at=512)

doc(accuracy_multi)

model = BaseModelWrapper(hf_model)
 
acc_02 = partial(accuracy_multi, thresh=0.2)

learner = Learner(dls, 
                  model,
                  opt_func=partial(OptimWrapper, opt=torch.optim.AdamW),
                  loss_func=BCEWithLogitsLossFlat(),
                  metrics=[acc_02],
                  cbs=[BaseModelCallback],
                  splitter=blurr_splitter
                  ).to_fp16()

learner.freeze()

learner.lr_find(suggest_funcs=[slide, valley])

learner.fit_one_cycle(2,1e-3)

learner.save("/content/drive/MyDrive/imdb_everything/models/imdb-classifier-stage-0")

learner.export("/content/drive/MyDrive/imdb_everything/models/imdb-classifier-stage-0.pkl")



"""# Stage - 1 

"""

learner.unfreeze()

learner.lr_find(suggest_funcs=[slide, valley])

learner.fit_one_cycle(5,slice(2e-3, 4.6e-5))

learner.save("/content/drive/MyDrive/imdb_everything/models/imdb-classifier-stage-1")

learner.export("/content/drive/MyDrive/imdb_everything/models/imdb-classifier-stage-1.pkl")

